---
author: 'hga'
title: 'How do swarms invent?'
description: 'The committee is agents now but Conway''s Law still applies.'
category: 'ai'
layout: '../../layouts/BlogPost.astro'
publishedDate: '2026-02-21'
heroImage: 'how-do-swarms-invent.jpg'
tags:
  - 'ai'
  - 'agentic coding'
  - 'engineering'
  - 'architecture'
---

<p class="lede">In 1967, <a href="https://www.melconway.com/Home/Conways_Law.html" target="_blank">Melvin Conway</a> submitted a paper to the <em>Harvard Business Review</em> arguing that any organisation designing a system will produce a design that mirrors its own communication structure. The paper was called "How Do Committees Invent?"</p>

The committee [rejected it](https://www.melconway.com/Home/pdf/committees.pdf). [Fred Brooks](https://en.wikipedia.org/wiki/The_Mythical_Man-Month), author of *The Mythical Man-Month*, named it Conway's Law a few years later, and six decades of evidence have made it hard to dispute. Increasingly, the committee is a [swarm of agents](/blog/from-specification-to-stress-test) with a single human operator, if that. Conway's Law says designs mirror their creators. What happens when the creators are LLMs?

## Good fences make good neighbours

LLMs write good code. By most measures, better than many humans. Give one overarching goals and ask it to plan, and the architectural results are surprisingly coherent. [Research into agentic software architecture](https://arxiv.org/pdf/2509.08646) finds that a planning agent that decomposes a problem before worker agents execute consistently outperforms uncoordinated generation. Humans aren't especially good at architecture either: controlled experiments find [cognitive biases](https://www.researchgate.net/publication/317433924_On_Cognitive_Biases_in_Architecture_Decision_Making) in architectural decision-making, from anchoring on familiar solutions to optimism about preferred approaches, and experienced practitioners are [more susceptible than students](https://arxiv.org/html/2502.04011v1). An LLM with a plan might have the edge.

<span class="pullquote" text-content="The question isn't what happens when a single agent plans a project. It's what happens when multiple agents build a system piecemeal."></span>But the question isn't what happens when a single agent plans a whole project. It's what happens when multiple agents are given pieces of work piecemeal and asked to build a system together. This is the territory [*The Mythical Man-Month*](https://en.wikipedia.org/wiki/The_Mythical_Man-Month) warns about: communication channels [scale as n(n-1)/2](https://en.wikipedia.org/wiki/Brooks%27s_law), and adding people to a late project makes it later. Replace "people" with "agents" and the arithmetic doesn't change. Two thousand agents create nearly two million communication pairs, not because any agent writes badly, but because nobody is routing the calls.

An LLM working on its piece will happily generate a module that handles authentication, logging and billing in one place. Conway's Law would predict as much: a model whose neurons are [polysemantic by nature](https://transformer-circuits.pub/2023/monosemantic-features), each one responding to a [tangle of unrelated concepts](https://arxiv.org/abs/2505.11581), is not going to lose sleep over a component that does six things.

## The sorcerer's apprentice

Rich Hickey makes the case that [easy and simple are not the same thing](https://www.infoq.com/presentations/Simple-Made-Easy/). Easy is whatever produces working output fastest, whatever you're used to doing. Simple is whatever keeps concerns separated. Simple might be very hard. [Dijkstra](https://www.cs.utexas.edu/~EWD/transcriptions/EWD08xx/EWD896.html) put it bluntly: "Simplicity is a great virtue but it requires hard work to achieve it and education to appreciate it. And to make matters worse: complexity sells better."

[Tony Hoare](https://en.wikipedia.org/wiki/Tony_Hoare) made a complementary observation in his [1980 Turing Award lecture](https://dl.acm.org/doi/10.1145/358549.358561): "There are two ways of constructing a software design: One way is to make it so simple that there are obviously no deficiencies, and the other way is to make it so complicated that there are no obvious deficiencies."

<span class="pullquote left" text-content="Easy is whatever the model generates most naturally. Simple requires deliberate subtraction that nobody specified."></span>The intuitive objection: if LLMs can generate and fix code so quickly, does complexity matter? It does, for the same reasons it always has. Complexity resists *change*, and change resistance is the real cost. Professional developers spend [roughly 58% of their working time](https://www.researchgate.net/publication/318811113_Measuring_Program_Comprehension_A_Large-Scale_Field_Study_with_Professionals) on program comprehension alone. Those proportions don't shift when the reader parsing the code is an LLM, and the evidence suggests AI makes it worse: a [2025 study of Cursor adoption](https://arxiv.org/abs/2511.04427) in open-source projects found a 42% increase in cognitive complexity, alongside a velocity boost that faded within months. Easy is whatever the model generates most naturally. Simple requires deliberate subtraction that nobody specified.

Cursor's [FastRender](https://github.com/nickelcat/nickelcat-fast-render) showed the extreme case: two thousand agents produced three million lines of entangled Rust that a Servo maintainer [called](https://simonwillison.net/2026/Jan/23/fastrender/) "a tangle of spaghetti", three times the size of [Servo](https://servo.org/) for a fraction of its capability.

In 1965, the same Hoare who articulated the design principle added null references to ALGOL W "simply because it was so easy to implement". He later called it his [billion-dollar mistake](https://www.infoq.com/presentations/Null-References-The-Billion-Dollar-Mistake-Tony-Hoare/). Sixty years on, most languages carry the idea of null and the bugs that come with it. One committee member's shortcut, embedded across the entire discipline.

Languages without null exist: Rust, Kotlin, Haskell and Swift. You could vibe-code a null-free language in a weekend, but the language is the easy part. This is Conway's Law applied to the discipline itself: the community's communication structures, from shared libraries and interop boundaries to hiring pipelines and developer habits, have null baked in at every layer. Coordinated change across an ecosystem that large costs more than living with the damage. At the scale agents operate, every expedient choice is a candidate for the same permanence.

## Thereafter they shape us

"We shape our tools and thereafter they shape us" is [often attributed](https://quoteinvestigator.com/2016/06/26/shape/) to Marshall McLuhan. The words are actually John Culkin's, from a [1967 article](https://en.wikipedia.org/wiki/John_Culkin) explaining McLuhan's ideas to educators, building on Churchill's observation that "we shape our buildings and afterwards our buildings shape us". The misattribution sticks because the sentiment captures McLuhan's thinking perfectly. Either way, the claim deserves scrutiny. How, concretely, do the structural decisions of an LLM shape the people who inherit its output?

Some persistence is benign. The [QWERTY keyboard](https://en.wikipedia.org/wiki/QWERTY) was designed in the 1870s to prevent typewriter jams; the jams are 150 years gone, the layout is on every touchscreen. British [area codes](https://en.wikipedia.org/wiki/Telephone_numbers_in_the_United_Kingdom#History) still echo the letters on a rotary dial: Aylesbury became 0296 because A maps to 2 and Y to 9. [Standard railroad gauge](https://en.wikipedia.org/wiki/Standard-gauge_railway) was set by English colliery tramways. Designers call these [skeuomorphs](https://en.wikipedia.org/wiki/Skeuomorph): interfaces that mimic their obsolete predecessors, like the shutter-click on a phone camera. Biologists have [vestiges](https://en.wikipedia.org/wiki/Vestigiality) and [atavisms](https://en.wikipedia.org/wiki/Atavism); linguists have [fossil words](https://en.wikipedia.org/wiki/Fossil_word) like "bated" in "bated breath". That English needs so many terms for things that outlive their purpose says something about how common the pattern is. QWERTY works fine. The area codes are charming. These are design hangovers, not constraints.

Paul David [documented](https://www.researchgate.net/publication/4724731_The_Dynamo_and_the_Computer_An_Historical_Perspective_On_the_Modern_Productivity_Paradox) a different kind of persistence in factory electrification. Steam-era plants used multi-storey layouts because power came from a single engine distributing force through shafts and belts; the building was shaped by the engine. When electricity arrived, managers replaced the steam engine with an electric dynamo but kept the multi-storey layout and the belt system. They overlaid the new technology on the old structure, and productivity barely changed. The surge came only in the 1920s, four decades after electrification, when factories were redesigned from scratch for "unit drive": individual motors on individual machines, enabling single-storey layouts where work could flow in a line. Did the managers know they were constrained? David's research suggests it wasn't pure cognitive blindness. They were partly captured by existing patterns, weighted by sunk costs, lacking a mental model for how the new technology could reshape the work itself. Not blind, but constrained in their seeing.

Null follows the same pattern at the scale of an entire discipline. **Organisational structure long outlives the decisions that created it.**

Which kind of persistence is LLM-generated code creating? In late 2025, Peter Steinberger [vibe-coded](https://fortune.com/2026/01/31/ai-agent-moltbot-clawdbot-openclaw-data-privacy-security-nightmare-moltbook-social-network/) a WhatsApp relay script in about an hour. It became [OpenClaw](https://github.com/nickelcat/openclaw), which grew to over 200,000 GitHub stars in weeks. Its architecture, a hub-and-spoke WebSocket gateway binding to port 18789 with a custom wire protocol, was shaped by a single conversation with an LLM. That architecture is now being [studied as a template](https://blog.agentailor.com/posts/openclaw-architecture-lessons-for-agent-builders) for agent infrastructure, with multiple frameworks replicating its design.

<span class="pullquote left" text-content="The architectural decisions of a single prompting session were constraining the security posture of a global network."></span>[Moltbook](https://fortune.com/2026/02/03/moltbook-ai-social-network-security-researchers-agent-internet/), a social network built on OpenClaw and also entirely vibe-coded, attracted over a million agent accounts within days. Its database was left completely open. SecurityScorecard found [over 135,000 internet-exposed OpenClaw instances](https://www.theregister.com/2026/02/09/openclaw_instances_exposed_vibe_code/) with their default configuration binding to the public internet. The architectural decisions of a single prompting session were constraining the security posture of a global network. The factory floor, four decades compressed into weeks.

## What committees leave behind

Conway submitted his paper about committees to a committee, and they rejected it. Six decades later, the question isn't whether the law holds. It's what it means when the committee is a swarm of agents.

OpenClaw might become foundational infrastructure, or it might be a footnote within a year. Conway's Law predicts the distinction matters less than you'd think, because everything built on top of that first hour of vibe-coding makes the underlying decisions more expensive to change. The layout outlasts the engine. The area code outlasts the rotary dial.

There's a [popular thesis](https://en.wikipedia.org/wiki/Vibe_coding) that AI will make code disposable, single-use plastic that you generate and throw away. Perhaps, for ephemeral tooling. But Hoare didn't leave behind sixty years of code. He left behind sixty years of an *idea*. You can rewrite the implementation from scratch and the new version will still carry the imprint of the committee that designed it. [Conway's Law](https://en.wikipedia.org/wiki/Conway%27s_law) doesn't fossilise code. It fossilises ideas, and those survive any rewrite.

<span class="pullquote" text-content="If you don't design the exchange, the LLM's context window becomes the exchange."></span>Every agent swarm is building an exchange, whether its operator designs it or not. If you don't design the exchange, the LLM's context window becomes the exchange. These principles have shaped [how we approach AI-assisted engineering at JUXT](/). If you'd like help taking control of the structure, [we'd welcome a conversation](mailto:info@juxt.pro?subject=AI-assisted%20engineering).
