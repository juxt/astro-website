---
author: 'hga'
title: 'How do swarms invent?'
description: 'We''re forming our AIs into committees. Conway''s Law still applies.'
category: 'ai'
layout: '../../layouts/BlogPost.astro'
publishedDate: '2026-02-21'
heroImage: 'how-do-swarms-invent.jpg'
tags:
  - 'ai'
  - 'agentic coding'
  - 'engineering'
  - 'architecture'
---

<p class="lede">In 1967, <a href="https://www.melconway.com/Home/Conways_Law.html" target="_blank">Melvin Conway</a> submitted a paper to the <em>Harvard Business Review</em> arguing that any organisation designing a system will produce a design that mirrors its own communication structure. The paper was called "How Do Committees Invent?"</p>

The committee [rejected it](https://www.melconway.com/Home/pdf/committees.pdf). [Fred Brooks](https://en.wikipedia.org/wiki/The_Mythical_Man-Month), author of *The Mythical Man-Month*, named it Conway's Law a few years later, and six decades of evidence have made it hard to dispute. Increasingly, the committee is a [swarm of agents](/blog/from-specification-to-stress-test) with a single human operator, if that. Conway's Law says designs mirror their creators. What happens when the creators are LLMs?

## Good fences make good neighbours

LLMs write good code. By most measures, better than many humans. Give one an overarching goal and ask it to plan, and the architectural results are surprisingly coherent. [Research into agentic software architecture](https://arxiv.org/pdf/2509.08646) finds that a planning agent that decomposes a problem before worker agents execute consistently outperforms uncoordinated generation. Humans bring [cognitive biases](https://www.researchgate.net/publication/317433924_On_Cognitive_Biases_in_Architecture_Decision_Making) to architectural decision-making, from anchoring on familiar solutions to optimism about preferred approaches, and experienced practitioners are [more susceptible than students](https://arxiv.org/html/2502.04011v1). An LLM with a plan might have the edge in design as well as implementation.

<span class="pullquote" text-content="Simplification is hard, lonely work, and it doesn't parallelise."></span>That edge depends on the plan existing. Without deliberate upfront design, the defaults take over. An LLM working on its piece will happily generate a module that handles authentication, logging and billing in one place. Conway's Law would predict as much: a model whose neurons are [polysemantic by nature](https://transformer-circuits.pub/2023/monosemantic-features), each one responding to a [tangle of unrelated concepts](https://arxiv.org/abs/2505.11581), is not going to lose sleep over a component that does six things. Simplification is hard, lonely work, and it doesn't parallelise.

[Rich Hickey](https://www.infoq.com/presentations/Simple-Made-Easy/) makes the case that easy and simple are not the same thing. Easy is whatever produces working output fastest, whatever you're used to doing. Simple is whatever keeps concerns separated. Simple might be very hard. Hickey's "easy" is Shakespeare's [primrose path](https://en.wikipedia.org/wiki/Primrose_path): the pleasant road to somewhere you'd rather not arrive. [Tony Hoare](https://en.wikipedia.org/wiki/Tony_Hoare) described the two paths in his [1980 Turing Award lecture](https://dl.acm.org/doi/10.1145/358549.358561): "There are two ways of constructing a software design: One way is to make it so simple that there are obviously no deficiencies, and the other way is to make it so complicated that there are no obvious deficiencies."

## The primrose path

<span class="pullquote left" text-content="Easy is whatever the model generates most naturally. Simple requires deliberate subtraction that nobody specified."></span>Cursor's [FastRender](https://github.com/nickelcat/nickelcat-fast-render) showed where the path leads. Two thousand agents produced three million lines of entangled Rust that a Servo maintainer [called](https://simonwillison.net/2026/Jan/23/fastrender/) "a tangle of spaghetti", three times the size of [Servo](https://servo.org/) for a fraction of its capability. A [2025 study of Cursor adoption](https://arxiv.org/abs/2511.04427) in open-source projects found a 42% increase in cognitive complexity, alongside a velocity boost that faded within months. Easy is whatever the model generates most naturally. Simple requires deliberate subtraction that nobody specified.

The arithmetic of *The Mythical Man-Month* explains why. Communication channels [scale as n(n-1)/2](https://en.wikipedia.org/wiki/Brooks%27s_law), and adding people to a late project makes it later. Replace "people" with "agents" and nothing changes. Those two thousand agents created nearly two million communication pairs, not because any agent writes badly, but because nobody was routing the calls. No amount of parallel horsepower can rescue a design that was never made. And the resulting tangle constrains whatever comes next: an AI asked to modify FastRender faces the same cascading breakage a human would. Complexity doesn't care who's struggling with it.

## As the twig is bent, so grows the tree

Does code quality still matter if an LLM can always generate more code to manage the complexity it creates? There's a popular thesis that AI will make code disposable, single-use plastic that you generate and throw away. Perhaps, for ephemeral tooling. But Hoare didn't leave behind sixty years of code. He left behind sixty years of an *idea*. [Doug McIlroy](https://en.wikipedia.org/wiki/Douglas_McIlroy) didn't leave behind a C function. He left behind a way of thinking about [composition](https://en.wikipedia.org/wiki/Unix_philosophy). You can rewrite the implementation from scratch and the new version will still carry the imprint of the committee that designed it. [Conway's Law](https://en.wikipedia.org/wiki/Conway%27s_law) doesn't fossilise code. It fossilises ideas, and those survive any rewrite.

Paul David [documented](https://www.researchgate.net/publication/4724731_The_Dynamo_and_the_Computer_An_Historical_Perspective_On_the_Modern_Productivity_Paradox) how this plays out. Steam-era factories used multi-storey layouts because power came from a single engine distributing force through shafts and belts; the building was shaped by the engine. When electricity arrived, managers replaced the steam engine with an electric dynamo but kept the multi-storey layout. They overlaid the new technology on the old structure, and productivity barely changed. The real gains came only in the 1920s, four decades later, when factories were redesigned from scratch for individual motors on individual machines. The managers were partly captured by existing patterns and weighted by sunk costs, without a mental model for how the new technology could reshape the work itself.

In 1965, Hoare added null references to ALGOL W "simply because it was so easy to implement". He later called it his [billion-dollar mistake](https://www.infoq.com/presentations/Null-References-The-Billion-Dollar-Mistake-Tony-Hoare/). The cost comes from propagation: every function that receives a value must check whether it might be null, and every forgotten check is a crash. Languages without null exist, but the discipline's communication structures have null baked in at every layer. One committee member's shortcut, embedded across the profession for sixty years.

<span class="pullquote" text-content="The blast radius of an architectural idea can escape any single project and echo for generations."></span>A year earlier, McIlroy wrote a [memo proposing](https://en.wikipedia.org/wiki/Pipeline_(Unix)) that programs should connect "like garden hose". [Ken Thompson](https://en.wikipedia.org/wiki/Ken_Thompson) implemented them in Unix [overnight](https://www.princeton.edu/~hos/mike/transcripts/thompson.htm). Pipes created the philosophy of small, composable tools, and the pipeline metaphor runs through everything from functional programming to data engineering. Both were pragmatic decisions by individuals who couldn't have known their choices would still be shaping the discipline six decades later. When [Cerf](https://en.wikipedia.org/wiki/Vint_Cerf) and [Kahn](https://en.wikipedia.org/wiki/Bob_Kahn) designed [TCP/IP](https://en.wikipedia.org/wiki/Internet_protocol_suite), they spent years embedding [open standards and intelligence at the edges](https://en.wikipedia.org/wiki/End-to-end_principle), knowing their architecture would outlast any single implementation. **The blast radius of an architectural idea can escape any single project and echo for generations.**

## How committees invent

Conway submitted his paper about committees to a committee, and they rejected it. Six decades of evidence have settled the law. What does it mean when the committee is a swarm of agents making architectural decisions in minutes?

<span class="pullquote left" text-content="The architectural decisions of a single prompting session are already being replicated across the industry."></span>In late 2025, Peter Steinberger [vibe-coded](https://fortune.com/2026/01/31/ai-agent-moltbot-clawdbot-openclaw-data-privacy-security-nightmare-moltbook-social-network/) a WhatsApp relay script in about an hour. It became [OpenClaw](https://github.com/nickelcat/openclaw), which grew to over 200,000 GitHub stars in weeks. Its architecture, a hub-and-spoke WebSocket gateway binding to port 18789 with a custom wire protocol, emerged from a single conversation with an LLM. That architecture is now being [studied as a template](https://blog.agentailor.com/posts/openclaw-architecture-lessons-for-agent-builders) for agent infrastructure, with multiple frameworks replicating its design. [Moltbook](https://fortune.com/2026/02/03/moltbook-ai-social-network-security-researchers-agent-internet/), built on OpenClaw, attracted over a million agent accounts within days before security researchers found [over 135,000 internet-exposed instances](https://www.theregister.com/2026/02/09/openclaw_instances_exposed_vibe_code/) with the default configuration binding to the public internet. The architectural decisions of a single prompting session are already being replicated across the industry.

The [hub-and-spoke pattern](https://en.wikipedia.org/wiki/Star_network) might be the right shape for agent communication, the way pipes were right for program composition. Or the default binding to the public internet might be the next null: an expedient choice that every derivative system inherits because it was the first thing an LLM suggested. Conway's Law runs in both directions. By the time the answer is clear, the architecture will already have shaped the systems built on it and the engineers who build them. The layout outlasts the engine. Then the layout shapes the next engine.

Simplicity was never a concession to human limitations. It's what gives the next committee room to change direction. Which of the decisions your agents made today will your successors still be living with?

This question shapes [how we approach AI-assisted engineering at JUXT](/). If you'd like to think through the structure together, [we'd welcome a conversation](mailto:info@juxt.pro?subject=AI-assisted%20engineering).
