---
author: 'hga'
title: 'The layout outlasts the engine'
description: 'Code is fluid. The thinking it teaches is not.'
category: 'ai'
layout: '../../layouts/BlogPost.astro'
publishedDate: '2026-02-24'
heroImage: 'the-layout-outlasts-the-engine.jpg'
tags:
  - 'ai'
  - 'agentic coding'
  - 'engineering'
  - 'architecture'
---

<p class="lede"><a href="https://www.researchgate.net/publication/4724731_The_Dynamo_and_the_Computer_An_Historical_Perspective_On_the_Modern_Productivity_Paradox" target="_blank">Paul David</a> documented how steam-era factories were shaped by their engines. Power came from a single <a href="https://en.wikipedia.org/wiki/Line_shaft" target="_blank">shaft</a> turning on every floor; leather belts distributed force outward, and machines clustered near the shaft because every foot of belt lost energy. The whole building, several storeys tall, was an expression of the engine's constraints.</p>

When electricity arrived in the 1890s, owners bolted a [dynamo](https://en.wikipedia.org/wiki/Dynamo) where the engine had stood and changed nothing else. They kept the multi-storey buildings, the overhead shafts, the belt drives. Productivity barely moved. The gains came four decades later, when manufacturers redesigned from scratch for individual motors on individual machines: single-storey plants with floor plans dictated by workflow. The steam engine was gone, but its layout had persisted for forty years.

## Bolting the dynamo

<span class="pullquote" text-content="The constraint that shaped most software organisations was information scarcity."></span>Most organisations adopting AI are bolting the dynamo where the engine stood. They add copilots to existing workflows and agents to existing approval chains, and everyone agrees the real gains will come from redesigning rather than retrofitting. They're right, as far as it goes. The constraint that shaped most software organisations was information scarcity: knowledge had to travel through people, so you built review bottlenecks where one engineer held the system's mental model, and handoff processes where context was lost at every boundary. When agents can hold a full codebase in context, those structures become overhead.

But the manufacturers who did redesign for electric motors still chose where to put the walls. Every new layout becomes the next generation's inherited structure. Software has its own inherited layouts, assumptions embedded in architectures and frameworks that outlast the teams that created them. A [swarm of agents](/blog/from-specification-to-stress-test) can embed those assumptions in minutes. What happens when the layout propagates at LLM speed?

## The primrose path

Rich Hickey makes the case that [easy and simple are not the same thing](https://www.infoq.com/presentations/Simple-Made-Easy/). Easy is whatever produces working output fastest, whatever you're used to doing. Simple keeps concerns separated, and might be very hard. Hickey's "easy" is Shakespeare's [primrose path](https://en.wikipedia.org/wiki/Primrose_path): the pleasant road to somewhere you'd rather not arrive. An agent, left to choose, defaults to easy every time.

Cursor's [FastRender](https://github.com/nickelcat/nickelcat-fast-render) showed where the primrose path leads at scale. Two thousand agents, working without a coordinating design, produced three million lines of entangled Rust that a Servo maintainer [called](https://simonwillison.net/2026/Jan/23/fastrender/) "a tangle of spaghetti": three times the size of [Servo](https://servo.org/) for a fraction of its functionality, with an [88% CI failure rate](https://www.theregister.com/2026/01/22/cursor_ai_wrote_a_browser/). Each agent wrote code that [mimicked function in form](https://eu.36kr.com/en/p/3643187094507394) but lacked coherent engineering intention. Terzian [contrasted](https://pivot-to-ai.com/2026/01/27/cursor-lies-about-vibe-coding-a-web-browser-with-ai/) FastRender with Ladybird's codebase, which he could follow immediately because it tracked the web specifications. [Research into agentic architecture](https://arxiv.org/pdf/2509.08646) bears this out: without a coordinating design, agents consistently produce worse outcomes than those working from a plan. The issue was never capability. It was design.

<span class="pullquote" text-content="Simplification is hard, lonely work, and it doesn't parallelise."></span>Left to its own, an agent will add a dependency, wrap a problem in another layer, generate a module that handles three concerns at once. Each choice is locally rational and the code compiles. But complexity accretes without anyone intending it, and what starts as a shortcut becomes the structure everything else depends on. Each increment makes the next change harder. Simplification is hard, lonely work, and it doesn't parallelise. No amount of parallel horsepower can rescue a design that was never made. An AI asked to modify FastRender faces the same cascading breakage a human would. **Complexity doesn't care who's struggling with it.**

## As the twig is bent

<span class="pullquote" text-content="The most durable output of any design is the thinking embedded in it."></span>Code is supposed to be fluid. You can rewrite it, replace whole systems, and that's why bad decisions should be temporary. But while code is fluid, the thinking it teaches is not. The most durable output of any design is the thinking embedded in it.

In 1965, Hoare added null references to ALGOL W "simply because it was so easy to implement". He later called it his [billion-dollar mistake](https://www.infoq.com/presentations/Null-References-The-Billion-Dollar-Mistake-Tony-Hoare/). The cost is in its propagation: every function that receives a reference must check whether it might be null, and every forgotten check is a potential crash. Languages without null exist and have for decades. [Rust](https://doc.rust-lang.org/book/ch06-01-defining-an-enum.html#the-option-enum-and-its-advantages-over-null-values), [Haskell](https://wiki.haskell.org/Maybe) and [Kotlin](https://kotlinlang.org/docs/null-safety.html) prove the implementation is replaceable. But sixty years on, most programmers still reach for null when they need to represent absence, because the code taught them how to think about data, and they taught the next generation. The mental model propagated through people faster than any language could displace it. Hoare's implementation took a day. **The thinking it introduced outlived every language that adopted it.**

[John Culkin](https://en.wikiquote.org/wiki/John_M._Culkin), writing about [Marshall McLuhan](https://en.wikipedia.org/wiki/Marshall_McLuhan) in 1967, [adapted Churchill's observation about buildings to technology](https://quoteinvestigator.com/2016/06/26/shape/): "We shape our tools and thereafter our tools shape us." Paul David's factory owners inherited more than a building layout. They inherited a way of thinking about what a factory *is*, and that thinking kept them building multi-storey plants for four decades after the steam engine was gone. The engine shaped the building, the building shaped the thinking, and the thinking persisted longest of all. Code carries the same pattern. Simple code leads to clear thinking, and clear thinking makes the next design decision easier. Complex code constrains the thinking of everyone who touches it next, human or AI alike. What kind of thinking is your codebase teaching the agents that work on it?

## Four decades to four weeks

<span class="pullquote left" text-content="An architectural idea can escape the project it was designed for and echo for generations."></span>[Cerf and Kahn](https://en.wikipedia.org/wiki/Internet_protocol_suite) embedded a deliberate philosophy in TCP/IP: keep the network simple, push [intelligence to the edges](https://en.wikipedia.org/wiki/End-to-end_principle), let any device that speaks the open protocol participate. The network routes packets; what the endpoints do with them is their business. That simplicity meant the internet didn't need to be redesigned for the web, or for mobile, or for streaming, or for IoT. Each new use composed with the existing protocols because the infrastructure had been designed to allow composition. **An architectural idea can escape the project it was designed for and echo for generations.**

In late 2025, Peter Steinberger [vibe-coded](https://fortune.com/2026/01/31/ai-agent-moltbot-clawdbot-openclaw-data-privacy-security-nightmare-moltbook-social-network/) a WhatsApp relay script in about an hour. It became [OpenClaw](https://github.com/nickelcat/openclaw), which crossed 200,000 GitHub stars in weeks, its architecture now [replicated as a template](https://blog.agentailor.com/posts/openclaw-architecture-lessons-for-agent-builders) for agent infrastructure. That architecture inverts TCP/IP's design: it centralises intelligence at the hub rather than distributing it to the edges, replaces open protocols with proprietary frames and assumes trust by default. These are values embedded in the architecture, shaped by the problem OpenClaw was built to solve. But values propagate, intended or not.

The propagation is already visible. [Moonshot AI's Kimi Claw](https://www.marktechpost.com/2026/02/15/moonshot-ai-launches-kimi-claw-native-openclaw-on-kimi-com-with-5000-community-skills-and-40gb-cloud-storage-now/) brought the full architecture to a cloud-native platform: the centralised hub, the [skill registry](https://github.com/VoltAgent/awesome-openclaw-skills), the trust model. Developers adopted the template because it worked, inheriting assumptions they hadn't examined. Those assumptions shaped what followed: [over 800 malicious skills](https://www.theregister.com/2026/02/03/openclaw_security_problems) in the registry within weeks, [over 40,000 instances](https://www.bitsight.com/blog/openclaw-ai-security-risks-exposed-instances) running with authentication disabled because the default was trust. When the creator of [NanoClaw](https://venturebeat.com/orchestration/nanoclaw-solves-one-of-openclaws-biggest-security-issues-and-its-already) tried to harden the original, he found 400,000 lines with assumptions so deeply embedded that patching wasn't viable. He rewrote the core to 500 lines, the equivalent of redesigning the factory for individual motors.

Paul David's factory owners needed four decades to shed the steam engine's layout. OpenClaw compressed the same cycle into weeks. By the time the constraints were obvious, the architecture had already shaped the next generation of systems. **The layout outlasts the engine. Then the layout shapes the next engine.**

Simplicity was never a concession to human limitations. It's what keeps designs open and gives the next builder room to change direction. Which of the decisions your agents made today will your successors still be living with?

This question shapes [how we approach AI-assisted engineering at JUXT](/). If you'd like to think through the structure together, [we'd welcome a conversation](mailto:info@juxt.pro?subject=AI-assisted%20engineering).
