---
author: 'hga'
title: 'The Gradient of Interesting'
description: 'Watch Henry Garner discuss why intelligent systems often optimise the wrong objective [video].'
category: 'conference'
layout: '../../layouts/BlogPost.astro'
publishedDate: '2026-02-18'
heroImage: 'the-gradient-of-interesting.jpg'
tags:
  - 'fintech'
  - 'conference'
  - 'AI'
  - 'tech talks'
---

Filing cabinets and lightbulbs aren't the obvious route into software engineering.

As the year winds down, I've been thinking about my somewhat unconventional path into the industry. At JUXT, we take any in-person get-together as an opportunity for a tech conference, and this includes our Christmas Party.

Inspired by our venue (the Quantum Untangled exhibition at the Science Gallery London) I used my talk to share some of my personal story, and the Big Ideas I was wrestling with as an arts undergraduate.

Some of the biggest ideas came to me via the books of David Deutsch. For example, his thesis behind The Beginning of Infinity is that the scientific revolution wasn't just a significant cultural moment for humanity; it was a significant moment in the universe itself. Once humans became focused on identifying good explanations, the world entered a period of potentially unbounded progress.

Why do we see such polarisation between those who wield AI despite its flaws and those who are fervently anti-AI despite its extraordinary successes? I wonder if it has to do with intuitions about the quality of explanations. Human progress is full of incredibly useful models that turned out to be absolutely wrong: the geocentric model of the universe, for example. Seasoned technical people, especially, have a deep aesthetic objection to anything that seems predicated on flawed explanations.

I share some of my own disappointments and concerns about the current state of the AI industry, but above all my excitement that we simply can't know where the next stepping stones will come from. Whether current AI models turn out to be an evolutionary dead-end or the basis of ever more powerful intelligence, we can only connect the dots in hindsight.

We didn't know that the technology for making reading glasses would lead to Galileo's telescopes and the end of the geocentric model, or that the valves for amplifying telephone signals would enable the first electronic computers.

We're still early, and there will always be problems to solve.

As Alan Kay said, the best way to predict the future is to invent it.

My full talk is now available on YouTube:

<iframe class='aspect-video w-full' src="https://www.youtube.com/embed/ZONNfszeHyM?si=KWBPU9TvhyXkKXh3" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

You can access my slides <a href="/tech-talks-25/henry-garner.pdf" target="_blank">here.</a>

If you have any questions or would like to discuss the ideas further, feel free to reach out to me at hgarner@griddynamics.com.
