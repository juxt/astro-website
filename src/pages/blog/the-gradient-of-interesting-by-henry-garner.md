---
author: 'hga'
title: 'The Gradient of Interesting'
description: 'Watch Henry Garner discuss why intelligent systems often optimise the wrong objective [video].'
category: 'conference'
layout: '../../layouts/BlogPost.astro'
publishedDate: '2026-02-03'
heroImage: 'the-gradient-of-interesting.jpg'
tags:
  - 'fintech'
  - 'conference'
  - 'AI'
  - 'tech talks'
---

This talk grew out of a question I keep coming back to: why do smart systems, human or machine, so often get stuck on the wrong things?

We tend to move in the direction that feels most interesting right now. That works surprisingly well, until it doesn’t. In science, in technology, and in machine learning, progress often looks like hill-climbing. You follow the slope in front of you, not knowing whether there’s a higher peak somewhere else.

I touch on examples from the history of science, early skepticism toward new tools, and modern machine learning systems that optimise confidently while missing the point. These failures aren’t accidents. They’re a natural outcome of learning in complex spaces where checking whether you’re right is expensive or unclear.

The talk isn’t an argument against optimisation or curiosity. It’s more a reminder that “interesting” is a local signal, not a guarantee of truth. Knowing that can change how we build systems, and how much confidence we place in their outputs.

My full talk is now available on YouTube:

<iframe class='aspect-video w-full' src="https://www.youtube.com/embed/ZONNfszeHyM?si=KWBPU9TvhyXkKXh3" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

You can access my slides <a href="/tech-talks-25/henry-garner.pdf" target="_blank">here.</a>

If you have any questions or would like to discuss the ideas further, feel free to reach out to me at hgarner@griddynamics.com.
