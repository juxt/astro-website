---
layout: '../../../layouts/ChildSectionAiRadar.astro'
title: 'Languages & Frameworks: Adopt'
---

# Adopt

These languages and frameworks represent mature, well-supported technologies that are ready for production use. They offer excellent performance, extensive ecosystems, and proven track records in real-world applications.

<div data-radar data-meta='{"label":"PyTorch"}' />

## PyTorch

PyTorch has demonstrated consistent maturity and widespread adoption across both research and production environments, earning its place in our Adopt ring. We're seeing it emerge as the default choice for many machine learning teams, particularly those working on deep learning projects, thanks to its intuitive Python-first approach and dynamic computational graphs that make debugging and prototyping significantly easier.

The framework's robust ecosystem, exceptional documentation and strong community support make it a reliable choice for teams at any scale. While TensorFlow remains relevant, particularly in production deployments, PyTorch's seamless integration with popular machine learning tools, extensive pre-trained model repository and growing deployment options through TorchServe have addressed previous concerns about production readiness. The framework's adoption by major technology organisations and research institutions, coupled with its regular release cycle and stability, gives us confidence in recommending it as a default choice for new machine learning projects.

<div data-radar data-meta='{"label":"dbt"}' />

## dbt

We've placed dbt (data build tool) in the Adopt ring because it has proven to be an essential framework for organising and managing the data transformations that feed AI systems. dbt brings software engineering best practices like version control, testing, and documentation to data transformation workflows, which is crucial when preparing data for AI model training and inference.

The reliability and maintainability of AI systems heavily depend on the quality of their input data, and dbt helps teams achieve this by making data transformations more transparent and trustworthy. We've seen teams successfully use dbt to create clean, well-documented data pipelines that connect data warehouses to AI applications, while maintaining the agility to quickly adapt to changing requirements. Its integration with modern data platforms and strong community support make it a solid choice for organisations building out their AI infrastructure.

<div data-radar data-meta='{"label":"Anthropic Model Context Protocol"}' />

## Anthropic Model Context Protocol

We've placed Anthropic's Model Context Protocol (MCP) in the Adopt ring because it addresses a critical challenge in AI applications: the need for standardised integration between language models and external tools.

The Model Context Protocol provides a well-designed, consistent interface that allows developers to connect LLMs to various tools like databases, search engines, and data sources without having to reinvent integration patterns for each one. Based on our team's experience, this significantly reduces development time while improving reliability. The protocol's growing ecosystem of third-party tool integrations means developers can implement complex AI agent capabilities with minimal custom code, focusing instead on their application's unique value.

We're particularly impressed by how the protocol handles context management and tool discovery, helping models effectively reason about when and how to use available capabilities. Companies deploying AI assistants that need to interact with company data or perform specialised actions should seriously consider adopting this standard rather than building custom integration layers that will likely be more fragile and require more maintenance.
